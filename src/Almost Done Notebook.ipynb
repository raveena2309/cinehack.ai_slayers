{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "31cf0c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal Hate Speech Detection Pipeline - Fixed and Complete\n",
    "# Compatible with VS Code Jupyter Notebook\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "\n",
    "# Data & Numerical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import clip\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# ML & Clustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             roc_auc_score, roc_curve, precision_recall_curve,\n",
    "                             precision_recall_fscore_support, average_precision_score,\n",
    "                             silhouette_score, davies_bouldin_score)\n",
    "from sklearn.cluster import DBSCAN\n",
    "import xgboost as xgb\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# Web scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from io import BytesIO\n",
    "import re\n",
    "\n",
    "# Sentence Transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6b3736d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Device: cuda\n",
      "GPU Available: True\n",
      "GPU: NVIDIA GeForce RTX 2050\n",
      "CUDA Version: 12.8\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# 1. CONFIGURATION\n",
    "# ========================================================================\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Central configuration - MODIFY THESE PATHS FOR YOUR SETUP\"\"\"\n",
    "    \n",
    "    # ============ UPDATE THESE PATHS ============\n",
    "    json_dir: str = r\"D:\\B.Tech\\Hackathons\\CinehackAI\\Harmful Data\\POC DATA\\Text\"\n",
    "    images_dir: str = r\"D:\\B.Tech\\Hackathons\\CinehackAI\\Harmful Data\\POC DATA\\IMAGES\"\n",
    "    \n",
    "    # ============ JSON FIELD NAMES ============\n",
    "    text_field: str = \"img_text\"\n",
    "    id_field: str = \"id\"\n",
    "    label_field: str = \"label\"\n",
    "    \n",
    "    # ============ IMAGE MATCHING ============\n",
    "    image_matching: str = \"filename\"  # \"filename\", \"id_field\", or \"custom\"\n",
    "    \n",
    "    # ============ LABEL MAPPING ============\n",
    "    label_mapping: Dict[str, int] = None\n",
    "    default_label: int = 1  # 1 = hate, 0 = safe\n",
    "    \n",
    "    # ============ OTHER SETTINGS ============\n",
    "    cache_dir: str = \"./cache\"\n",
    "    models_dir: str = \"./models\"\n",
    "    results_dir: str = \"./results\"\n",
    "    \n",
    "    # Model settings\n",
    "    text_model: str = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "    image_model: str = \"clip\"\n",
    "    text_dim: int = 768\n",
    "    image_dim: int = 512\n",
    "    \n",
    "    # Processing\n",
    "    batch_size: int = 32\n",
    "    max_samples: int = None\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Dimensionality reduction\n",
    "    reduction_method: str = \"pca\"  # Changed to PCA for stability\n",
    "    reduced_dim: int = 50  # Reduced for small datasets\n",
    "    \n",
    "    # Clustering\n",
    "    eps: float = 0.5\n",
    "    min_samples: int = 3  # Reduced for small datasets\n",
    "    \n",
    "    # Classification\n",
    "    test_size: float = 0.2\n",
    "    random_state: int = 42\n",
    "    \n",
    "    def _post_init_(self):\n",
    "        for dir_path in [self.cache_dir, self.models_dir, self.results_dir]:\n",
    "            Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config = Config()\n",
    "\n",
    "print(f\"\\nDevice: {config.device}\")\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee821e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 2. DATA LOADER\n",
    "# ========================================================================\n",
    "\n",
    "class JSONDataLoader:\n",
    "    \"\"\"Load and preprocess dataset from JSON files + images\"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "\n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean and normalize text\"\"\"\n",
    "        if pd.isna(text) or not isinstance(text, str):\n",
    "            return \"\"\n",
    "        text = re.sub(r'<[^>]+>', '', text)\n",
    "        text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "        text = re.sub(r'[^\\w\\s,.!?-]', '', text)\n",
    "        text = ' '.join(text.split())\n",
    "        return text.strip()\n",
    "\n",
    "    def load_json_file(self, file_path: Path) -> Dict:\n",
    "        \"\"\"Load a single JSON file\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_image_path(self, json_file: Path, json_data: Dict) -> Optional[Path]:\n",
    "        \"\"\"Determine corresponding image path\"\"\"\n",
    "        if self.config.image_matching == \"filename\":\n",
    "            image_name = json_file.stem + \".jpg\"\n",
    "            image_path = Path(self.config.images_dir) / image_name\n",
    "        elif self.config.image_matching == \"id_field\":\n",
    "            if self.config.id_field in json_data:\n",
    "                image_name = str(json_data[self.config.id_field]) + \".jpg\"\n",
    "                image_path = Path(self.config.images_dir) / image_name\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            image_name = json_file.stem + \".jpg\"\n",
    "            image_path = Path(self.config.images_dir) / image_name\n",
    "        \n",
    "        return image_path if image_path.exists() else None\n",
    "\n",
    "    def get_label(self, json_data: Dict) -> int:\n",
    "        \"\"\"Extract label from JSON data\"\"\"\n",
    "        if self.config.label_field and self.config.label_field in json_data:\n",
    "            label_value = json_data[self.config.label_field]\n",
    "            \n",
    "            if self.config.label_mapping:\n",
    "                return self.config.label_mapping.get(label_value, self.config.default_label)\n",
    "            \n",
    "            try:\n",
    "                return int(label_value)\n",
    "            except:\n",
    "                label_lower = str(label_value).lower()\n",
    "                if label_lower in ['hate', 'hateful', 'toxic', 'offensive', '1', 'true']:\n",
    "                    return 1\n",
    "                elif label_lower in ['safe', 'normal', 'clean', '0', 'false']:\n",
    "                    return 0\n",
    "                else:\n",
    "                    return self.config.default_label\n",
    "        \n",
    "        return self.config.default_label\n",
    "\n",
    "    def load_dataset(self) -> pd.DataFrame:\n",
    "        \"\"\"Load and preprocess dataset from JSON files\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"LOADING DATASET FROM JSON FILES\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        json_files = list(Path(self.config.json_dir).glob(\"*.json\"))\n",
    "        print(f\"Found {len(json_files)} JSON files in {self.config.json_dir}\")\n",
    "\n",
    "        if len(json_files) == 0:\n",
    "            raise FileNotFoundError(f\"No JSON files found in {self.config.json_dir}\")\n",
    "\n",
    "        data = []\n",
    "        skipped_no_text = 0\n",
    "        skipped_no_image = 0\n",
    "        skipped_error = 0\n",
    "\n",
    "        for json_file in tqdm(json_files, desc=\"Loading JSON files\"):\n",
    "            json_data = self.load_json_file(json_file)\n",
    "            if json_data is None:\n",
    "                skipped_error += 1\n",
    "                continue\n",
    "\n",
    "            text = json_data.get(self.config.text_field, \"\")\n",
    "            if not text or not isinstance(text, str):\n",
    "                skipped_no_text += 1\n",
    "                continue\n",
    "\n",
    "            cleaned_text = self.clean_text(text)\n",
    "            if len(cleaned_text) == 0:\n",
    "                skipped_no_text += 1\n",
    "                continue\n",
    "\n",
    "            image_path = self.get_image_path(json_file, json_data)\n",
    "            if image_path is None or not image_path.exists():\n",
    "                skipped_no_image += 1\n",
    "                continue\n",
    "\n",
    "            label = self.get_label(json_data)\n",
    "\n",
    "            data.append({\n",
    "                \"filename\": json_file.name,\n",
    "                \"raw_text\": text,\n",
    "                \"cleaned_text\": cleaned_text,\n",
    "                \"image_path\": str(image_path),\n",
    "                \"hate_label\": label\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        if self.config.max_samples and len(df) > self.config.max_samples:\n",
    "            df = df.sample(n=self.config.max_samples, random_state=42).reset_index(drop=True)\n",
    "\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"DATASET LOADING SUMMARY\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Total JSON files found:     {len(json_files)}\")\n",
    "        print(f\"Skipped (no text):          {skipped_no_text}\")\n",
    "        print(f\"Skipped (no image):         {skipped_no_image}\")\n",
    "        print(f\"Skipped (errors):           {skipped_error}\")\n",
    "        print(f\"Successfully loaded:        {len(df)}\")\n",
    "        print(f\"\\nLabel distribution:\")\n",
    "        print(f\"  Hate samples (1):         {df['hate_label'].sum()} ({df['hate_label'].mean()*100:.1f}%)\")\n",
    "        print(f\"  Safe samples (0):         {(1-df['hate_label']).sum()} ({(1-df['hate_label'].mean())*100:.1f}%)\")\n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "        if len(df) == 0:\n",
    "            raise ValueError(\"No valid samples found!\")\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b606d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 3. SAFE PROMPT GENERATOR\n",
    "# ========================================================================\n",
    "\n",
    "class SafePromptGenerator:\n",
    "    \"\"\"Generate synthetic safe/non-hate prompts\"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state = random_state\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "        self.templates = {\n",
    "            'questions': [\n",
    "                \"How do I learn {}?\",\n",
    "                \"What's the best way to {}?\",\n",
    "                \"Can you explain {} to me?\",\n",
    "                \"I'm interested in learning about {}\",\n",
    "                \"What are some good resources for {}?\"\n",
    "            ],\n",
    "            'topics': [\n",
    "                'cooking', 'programming', 'photography', 'gardening', 'music',\n",
    "                'painting', 'writing', 'exercise', 'meditation', 'reading',\n",
    "                'traveling', 'languages', 'science', 'history', 'mathematics'\n",
    "            ],\n",
    "            'positive': [\n",
    "                \"I love learning new things\",\n",
    "                \"This is so interesting\",\n",
    "                \"Thank you for your help\",\n",
    "                \"I appreciate your assistance\",\n",
    "                \"That's very helpful information\"\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def generate(self, n_samples: int, placeholder_image: str) -> pd.DataFrame:\n",
    "        \"\"\"Generate n_samples of safe prompts\"\"\"\n",
    "        texts = []\n",
    "        image_paths = []\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            if i % 3 == 0:\n",
    "                text = np.random.choice(self.templates['positive'])\n",
    "            else:\n",
    "                template = np.random.choice(self.templates['questions'])\n",
    "                topic = np.random.choice(self.templates['topics'])\n",
    "                text = template.format(topic)\n",
    "            \n",
    "            texts.append(text)\n",
    "            image_paths.append(placeholder_image)  # Use actual image\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'cleaned_text': texts,\n",
    "            'image_path': image_paths,\n",
    "            'hate_label': 0\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "497d66b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 4. TEXT EMBEDDER\n",
    "# ========================================================================\n",
    "\n",
    "class TextEmbedder:\n",
    "    \"\"\"Extract text embeddings using SentenceTransformers\"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.device = config.device\n",
    "        print(\"\\nLoading Sentence-BERT model...\")\n",
    "        self.model = SentenceTransformer(config.text_model, device=self.device)\n",
    "        print(f\"Model loaded on {self.device}\")\n",
    "\n",
    "    def embed_texts(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"Generate embeddings for texts\"\"\"\n",
    "        return self.model.encode(\n",
    "            texts,\n",
    "            batch_size=self.config.batch_size,\n",
    "            show_progress_bar=True,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3b2acfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 5. IMAGE EMBEDDER\n",
    "# ========================================================================\n",
    "\n",
    "class ImageEmbedder:\n",
    "    \"\"\"Extract image embeddings using CLIP\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.device = torch.device(config.device)\n",
    "        \n",
    "        print(\"\\nLoading CLIP model...\")\n",
    "        if config.image_model == \"clip\":\n",
    "            self.model, self.preprocess = clip.load(\"RN50\", device=self.device)\n",
    "            self.model.eval()\n",
    "        print(f\"Model loaded on {self.device}\")\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def embed_images(self, image_paths: List[str]) -> np.ndarray:\n",
    "        \"\"\"Generate embeddings for images\"\"\"\n",
    "        embeddings = []\n",
    "        \n",
    "        for img_path in tqdm(image_paths, desc=\"Image embeddings\"):\n",
    "            try:\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "                image_tensor = self.preprocess(image).unsqueeze(0).to(self.device)\n",
    "                features = self.model.encode_image(image_tensor)\n",
    "                features = features.squeeze().cpu().numpy()\n",
    "                features = features / (np.linalg.norm(features) + 1e-8)\n",
    "                embeddings.append(features)\n",
    "            except Exception as e:\n",
    "                print(f\"Error with {img_path}: {e}\")\n",
    "                embeddings.append(np.zeros(self.config.image_dim))\n",
    "        \n",
    "        return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a5e95d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 6. FUSION PROCESSOR\n",
    "# ========================================================================\n",
    "\n",
    "class FusionProcessor:\n",
    "    \"\"\"Fuse text and image embeddings\"\"\"\n",
    "    \n",
    "    def __init__(self, fusion_method='concat'):\n",
    "        self.fusion_method = fusion_method\n",
    "    \n",
    "    def fuse(self, text_emb: np.ndarray, image_emb: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Fuse text and image embeddings\"\"\"\n",
    "        if text_emb.shape[0] != image_emb.shape[0]:\n",
    "            raise ValueError(f\"Dimension mismatch! Text: {text_emb.shape[0]}, Image: {image_emb.shape[0]}\")\n",
    "        \n",
    "        if self.fusion_method == 'concat':\n",
    "            fused = np.concatenate([text_emb, image_emb], axis=1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown fusion method: {self.fusion_method}\")\n",
    "        \n",
    "        print(f\"Fused: {text_emb.shape[1]}D + {image_emb.shape[1]}D = {fused.shape[1]}D\")\n",
    "        return fused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6e099a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 7. DIMENSIONALITY REDUCER\n",
    "# ========================================================================\n",
    "\n",
    "class DimensionalityReducer:\n",
    "    \"\"\"Reduce dimensions for clustering and visualization\"\"\"\n",
    "    \n",
    "    def __init__(self, method='pca', n_components=50, random_state=42):\n",
    "        self.method = method\n",
    "        self.n_components = n_components\n",
    "        self.random_state = random_state\n",
    "        self.reducer = None\n",
    "        self.reducer_2d = None\n",
    "    \n",
    "    def fit_transform(self, embeddings: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Reduce to n_components and create 2D projection\"\"\"\n",
    "        n_samples = embeddings.shape[0]\n",
    "        target_dim = min(self.n_components, n_samples - 1)\n",
    "        \n",
    "        if target_dim != self.n_components:\n",
    "            print(f\"Adjusting n_components from {self.n_components} to {target_dim}\")\n",
    "        \n",
    "        print(f\"Reducing from {embeddings.shape[1]}D to {target_dim}D...\")\n",
    "        \n",
    "        self.reducer = PCA(n_components=target_dim, random_state=self.random_state)\n",
    "        reduced = self.reducer.fit_transform(embeddings)\n",
    "        \n",
    "        self.reducer_2d = PCA(n_components=2, random_state=self.random_state)\n",
    "        embeddings_2d = self.reducer_2d.fit_transform(embeddings)\n",
    "        \n",
    "        print(f\"Reduced to {reduced.shape[1]}D\")\n",
    "        return reduced, embeddings_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fc125d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 8. CLASSIFIER\n",
    "# ========================================================================\n",
    "\n",
    "class HateSpeechClassifier:\n",
    "    \"\"\"XGBoost classifier\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.feature_importance = None\n",
    "        self.training_history = None\n",
    "    \n",
    "    def train(self, X_train, y_train, X_val, y_val):\n",
    "        \"\"\"Train XGBoost\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"TRAINING XGBOOST CLASSIFIER\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        scale_pos_weight = (y_train == 0).sum() / max((y_train == 1).sum(), 1)\n",
    "        print(f\"Training: {len(X_train)}, Validation: {len(X_val)}\")\n",
    "        \n",
    "        self.model = xgb.XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=4,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            random_state=self.config.random_state,\n",
    "            eval_metric=['auc', 'logloss']\n",
    "        )\n",
    "        \n",
    "        self.model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        y_pred_val = self.model.predict(X_val)\n",
    "        y_proba_val = self.model.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        print(\"\\nVALIDATION PERFORMANCE:\")\n",
    "        print(classification_report(y_val, y_pred_val, target_names=['Safe', 'Hate']))\n",
    "        \n",
    "        val_roc_auc = roc_auc_score(y_val, y_proba_val)\n",
    "        val_ap = average_precision_score(y_val, y_proba_val)\n",
    "        print(f\"ROC-AUC: {val_roc_auc:.4f}\")\n",
    "        print(f\"Average Precision: {val_ap:.4f}\")\n",
    "        \n",
    "        self.feature_importance = self.model.feature_importances_\n",
    "        \n",
    "        return {\n",
    "            'val': {\n",
    "                'y_pred': y_pred_val,\n",
    "                'y_proba': y_proba_val,\n",
    "                'roc_auc': val_roc_auc,\n",
    "                'avg_precision': val_ap,\n",
    "                'confusion_matrix': confusion_matrix(y_val, y_pred_val)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained!\")\n",
    "        return self.model.predict(X), self.model.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "76be9208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 9. CLUSTERING\n",
    "# ========================================================================\n",
    "\n",
    "class DBSCANClustering:\n",
    "    \"\"\"DBSCAN clustering\"\"\"\n",
    "    \n",
    "    def __init__(self, eps=0.5, min_samples=3):\n",
    "        self.eps = eps\n",
    "        self.min_samples = min_samples\n",
    "        self.model = None\n",
    "        self.labels = None\n",
    "    \n",
    "    def fit_predict(self, embeddings: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Fit DBSCAN\"\"\"\n",
    "        print(f\"\\nRunning DBSCAN (eps={self.eps}, min_samples={self.min_samples})...\")\n",
    "        \n",
    "        self.model = DBSCAN(eps=self.eps, min_samples=self.min_samples, n_jobs=-1)\n",
    "        self.labels = self.model.fit_predict(embeddings)\n",
    "        \n",
    "        n_clusters = len(set(self.labels)) - (1 if -1 in self.labels else 0)\n",
    "        n_noise = list(self.labels).count(-1)\n",
    "        \n",
    "        print(f\"Found {n_clusters} clusters, {n_noise} noise points\")\n",
    "        return self.labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "16c36ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 10. VISUALIZER\n",
    "# ========================================================================\n",
    "\n",
    "class Visualizer:\n",
    "    \"\"\"Create visualizations\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_clusters(embeddings_2d, cluster_labels, true_labels, output_dir):\n",
    "        \"\"\"Create cluster visualization\"\"\"\n",
    "        df_plot = pd.DataFrame({\n",
    "            'x': embeddings_2d[:, 0],\n",
    "            'y': embeddings_2d[:, 1],\n",
    "            'cluster': cluster_labels.astype(str),\n",
    "            'true_label': true_labels.astype(str)\n",
    "        })\n",
    "        \n",
    "        df_plot['label_name'] = df_plot['true_label'].map({'0': 'Safe', '1': 'Hate'})\n",
    "        \n",
    "        fig = px.scatter(\n",
    "            df_plot, x='x', y='y',\n",
    "            color='label_name',\n",
    "            title='2D Projection - True Labels',\n",
    "            color_discrete_map={'Safe': 'green', 'Hate': 'red'},\n",
    "            width=900, height=600\n",
    "        )\n",
    "        fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
    "        fig.write_html(output_dir / 'clusters.html')\n",
    "        print(f\"Saved visualization to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e34daa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 11. MAIN PIPELINE\n",
    "# ========================================================================\n",
    "\n",
    "def run_complete_pipeline(config: Config):\n",
    "    \"\"\"Run complete pipeline\"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    data_loader = JSONDataLoader(config)\n",
    "    df_harmful = data_loader.load_dataset()\n",
    "    \n",
    "    # Generate safe samples\n",
    "    print(\"\\nGenerating synthetic safe samples...\")\n",
    "    generator = SafePromptGenerator(random_state=config.random_state)\n",
    "    placeholder_img = df_harmful['image_path'].iloc[0]\n",
    "    df_safe = generator.generate(len(df_harmful), placeholder_img)\n",
    "    \n",
    "    # Combine\n",
    "    df = pd.concat([df_harmful, df_safe], ignore_index=True)\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    print(f\"Combined dataset: {len(df)} samples\")\n",
    "    print(f\"Hate: {(df['hate_label']==1).sum()}, Safe: {(df['hate_label']==0).sum()}\")\n",
    "    \n",
    "    # Text embeddings\n",
    "    text_cache = Path(config.cache_dir) / 'text_full.npy'\n",
    "    if text_cache.exists():\n",
    "        print(\"\\nLoading cached text embeddings...\")\n",
    "        text_embeddings = np.load(text_cache)\n",
    "    else:\n",
    "        text_embedder = TextEmbedder(config)\n",
    "        text_embeddings = text_embedder.embed_texts(df['cleaned_text'].tolist())\n",
    "        np.save(text_cache, text_embeddings)\n",
    "    print(f\"Text embeddings: {text_embeddings.shape}\")\n",
    "    \n",
    "    # Image embeddings\n",
    "    image_cache = Path(config.cache_dir) / 'image_full.npy'\n",
    "    if image_cache.exists():\n",
    "        print(\"\\nLoading cached image embeddings...\")\n",
    "        image_embeddings = np.load(image_cache)\n",
    "    else:\n",
    "        image_embedder = ImageEmbedder(config)\n",
    "        image_embeddings = image_embedder.embed_images(df['image_path'].tolist())\n",
    "        np.save(image_cache, image_embeddings)\n",
    "    print(f\"Image embeddings: {image_embeddings.shape}\")\n",
    "    \n",
    "    # Fusion\n",
    "    print(\"\\nFusing embeddings...\")\n",
    "    fusion_processor = FusionProcessor()\n",
    "    fused = fusion_processor.fuse(text_embeddings, image_embeddings)\n",
    "    \n",
    "    # Dimensionality reduction\n",
    "    print(\"\\nReducing dimensionality...\")\n",
    "    reducer = DimensionalityReducer(\n",
    "        method=config.reduction_method,\n",
    "        n_components=config.reduced_dim,\n",
    "        random_state=config.random_state\n",
    "    )\n",
    "    reduced, embeddings_2d = reducer.fit_transform(fused)\n",
    "    \n",
    "    # Clustering\n",
    "    clusterer = DBSCANClustering(eps=config.eps, min_samples=config.min_samples)\n",
    "    cluster_labels = clusterer.fit_predict(reduced)\n",
    "    \n",
    "    # Visualization\n",
    "    print(\"\\nCreating visualizations...\")\n",
    "    visualizer = Visualizer()\n",
    "    visualizer.plot_clusters(embeddings_2d, cluster_labels, df['hate_label'].values, \n",
    "                            Path(config.results_dir))\n",
    "    \n",
    "    # Classification\n",
    "    print(\"\\nTraining classifier...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        reduced, df['hate_label'].values,\n",
    "        test_size=config.test_size,\n",
    "        random_state=config.random_state,\n",
    "        stratify=df['hate_label'].values\n",
    "    )\n",
    "    \n",
    "    classifier = HateSpeechClassifier(config)\n",
    "    metrics = classifier.train(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PIPELINE COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return {\n",
    "        'df': df,\n",
    "        'classifier': classifier,\n",
    "        'reducer': reducer,\n",
    "        'metrics': metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b2f63445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LOADING DATASET FROM JSON FILES\n",
      "======================================================================\n",
      "Found 701 JSON files in D:\\B.Tech\\Hackathons\\CinehackAI\\Harmful Data\\POC DATA\\Text\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c229a327e8a4e0db64fe72d0637e17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading JSON files:   0%|          | 0/701 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATASET LOADING SUMMARY\n",
      "======================================================================\n",
      "Total JSON files found:     701\n",
      "Skipped (no text):          3\n",
      "Skipped (no image):         383\n",
      "Skipped (errors):           0\n",
      "Successfully loaded:        315\n",
      "\n",
      "Label distribution:\n",
      "  Hate samples (1):         315 (100.0%)\n",
      "  Safe samples (0):         0 (0.0%)\n",
      "======================================================================\n",
      "\n",
      "Generating synthetic safe samples...\n",
      "Combined dataset: 630 samples\n",
      "Hate: 315, Safe: 315\n",
      "\n",
      "Loading cached text embeddings...\n",
      "Text embeddings: (630, 768)\n",
      "\n",
      "Loading CLIP model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 244M/244M [04:40<00:00, 914kiB/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "bad allocation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_complete_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResults saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mresults_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[92], line 41\u001b[0m, in \u001b[0;36mrun_complete_pipeline\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     39\u001b[0m     image_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(image_cache)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m     image_embedder \u001b[38;5;241m=\u001b[39m \u001b[43mImageEmbedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     image_embeddings \u001b[38;5;241m=\u001b[39m image_embedder\u001b[38;5;241m.\u001b[39membed_images(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m     43\u001b[0m     np\u001b[38;5;241m.\u001b[39msave(image_cache, image_embeddings)\n",
      "Cell \u001b[1;32mIn[86], line 14\u001b[0m, in \u001b[0;36mImageEmbedder.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLoading CLIP model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mimage_model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess \u001b[38;5;241m=\u001b[39m \u001b[43mclip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRN50\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\clip\\clip.py:129\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, device, jit, download_root)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(model_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;66;03m# loading JIT archive\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    130\u001b[0m         state_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;66;03m# loading saved state dict\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\jit\\_serialization.py:172\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, _extra_files, _restore_shapes)\u001b[0m\n\u001b[0;32m    168\u001b[0m     cpp_module \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mimport_ir_module(\n\u001b[0;32m    169\u001b[0m         cu, os\u001b[38;5;241m.\u001b[39mfspath(f), map_location, _extra_files, _restore_shapes\n\u001b[0;32m    170\u001b[0m     )  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m     cpp_module \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_ir_module_from_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_extra_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_restore_shapes\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m# TODO: Pretty sure this approach loses ConstSequential status and such\u001b[39;00m\n\u001b[0;32m    177\u001b[0m ret \u001b[38;5;241m=\u001b[39m wrap_cpp_module(cpp_module)\n",
      "\u001b[1;31mMemoryError\u001b[0m: bad allocation"
     ]
    }
   ],
   "source": [
    "\n",
    "results = run_complete_pipeline(config)\n",
    "print(f\"\\nResults saved to: {config.results_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6990a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ========================================================================\n",
    "# 12. RUN PIPELINE\n",
    "# ========================================================================\n",
    "\n",
    "if _name_ == \"_main_\":"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
